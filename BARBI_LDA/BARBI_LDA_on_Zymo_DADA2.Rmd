---
title: "Zymbo Mock Community Data Analysis (16S rRNA gene amplicon sequencing) using BARBI LDA"
author: "Pratheepa Jeganathan"
date: "04/23/2019"
output: 
  html_document:
    toc: true
---

We have 10 negative control samples and serial dilution of ZymoBIOMICS® Microbial Community Standard.

Looking at the DADA2 pipeline ASVs 2, 3, 4, 5, 6, 7, 8, 11, 17, 37, 22 are in the ZymoBIOMICS® Microbial Community Standard.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.width = 18, fig.height = 12)
```

Loading packages
```{r}
library(phyloseq)
library(DESeq2)
library(ggplot2)
library(lda)
library(magrittr)
library(dplyr)
library(reshape2)
```

```{r}
set.theme = theme_update(panel.border = element_blank(),
                    panel.grid = element_line(size = .8),
                    axis.ticks = element_blank(),
                    legend.title = element_text(size = 8),
                    legend.text = element_text(size = 8),
                    axis.text = element_text(size = 8),
                    axis.title = element_text(size = 8),
                    strip.background = element_blank(),
                    strip.text = element_text(size = 8),
                    legend.key = element_blank(),
    plot.title = element_text(hjust = 0.5))
```

```{r}
theme_set(theme_bw())
```

Set the computational resources

```{r}
ncores = as.integer(Sys.getenv("SLURM_NTASKS"))
if(is.na(ncores)) ncores = parallel::detectCores()
ncores
```

## Read phyloseq and exploratory analysis

```{r}
ps = readRDS("./Data/ps_zymo.rds")
if(dim(otu_table(ps))[1]!=ntaxa(ps)){
  otu_table(ps) = t(otu_table(ps))
  }
```

change order of sample names
```{r}
ncont = paste0("NegativeControl.", seq(1, 10))
stan = paste0("Standard.Dilution.1.",c(1, 6, 36, 216, 1296, 7776, 46656, 279936))

sample_data(ps)$Name = factor(sample_data(ps)$Name, levels = c(ncont,stan))

sample_names(ps) = as.character(sample_data(ps)$Name)
```

Store sequence variants, ASVs, ASV.genus, ASV.genus.species
```{r}
ASV = as.character(paste0("ASV_", seq(1,ntaxa(ps))))

ASV.Genus = paste0("ASV_", seq(1,ntaxa(ps)), "_", as.character(tax_table(ps)[,6]))

ASV.Genus.Species = paste0(ASV, "_", as.character(tax_table(ps)[,6]), "_", as.character(tax_table(ps)[,7]))

df.ASV = data.frame(seq.variant = taxa_names(ps), ASV = ASV, ASV.Genus = ASV.Genus, ASV.Genus.Species = ASV.Genus.Species)
```


```{r }
taxa_names(ps) = df.ASV$ASV.Genus.Species
```

### Alpha diversity

```{r}
library(ggrepel)
ps.alpha = ps
Pi = c(18.58, 2.03, 14.91, .29, 13.68, 11.28, 14.59, 1.46, 8.43, 10.33, 4.42) # theoretical percentage of 11 species.
Pi = Pi/100
true.shannon.index = sum((Pi * log(Pi))*(-1))
true.shannon.index

name.label = c("","","1:1","1:6","1:(6^2)","1:(6^3)","1:(6^4)","1:(6^5)","1:(6^6)", "1:(6^7)",as.character(rep("",8)))
sample_data(ps.alpha)$name.label = name.label %>% factor


name.color = c("Negative Control", "Negative Control", "1:1", "1:6", "1:6^2", "1:6^3", "1:6^4", "1:6^5", "1:6^6", "1:6^7", as.character(rep("Negative Control",8)))
sample_data(ps.alpha)$name.color = name.color %>% factor

levels(sample_data(ps.alpha)$SampleType) = c("Negative Control", "Dilution")

col.manual = rainbow(9)

p = plot_richness(ps.alpha, x="SampleType", 
  measures = c("Shannon"), color = "name.label") + 
  geom_point(size = 3) +
  ylab("Shannon Index") + 
  scale_color_manual(values = c("blue", col.manual[-7]))  +
  xlab("Sample Type") +
  geom_text_repel(aes(label = name.label), size = 4, direction = "x") +
  theme(strip.text.x = element_blank(), legend.position = "none", axis.text.x = element_text(angle = -360)) + geom_hline (yintercept= true.shannon.index, colour="red", lty=6, lwd=1) 
p
```

### Microbial composition of the ZymoBIOMICS® Microbial Community Standard (Zymo Research, Irvine, CA) measured 

True ASVs at genus level

```{r}
# true.com.ASV = taxa_names(ps)[which(tax_table(ps)[,6] %in% c("Bacillus","Listeria","Staphylococcus", "Lactobacillus", "Escherichia/Shigella", "Enterococcus", "Salmonella", "Pseudomonas"))]
true.com.ASV = taxa_names(ps)[c(2:8,11,17,37,22)]
ps.true = transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.true = prune_taxa(true.com.ASV, ps.true)
ps.true
```

### Heatmap

```{r}
ps.top = ps 

ot = otu_table(ps.top) %>% data.frame %>% as.matrix
geo_mean = function(x) {
        if(all(x == 0)){
            val = 0
        }else{
            val = exp(sum(log(x[x > 0]))/length(x))
        }
        return(val)
    }

geom_mean_row = apply(ot, 1, FUN = geo_mean)


sj = estimateSizeFactorsForMatrix(ot, median, geoMeans = geom_mean_row)
ot.trans = t(asinh(t(ot)/sj))
ps.top = phyloseq(otu_table(ot.trans, taxa_are_rows = TRUE), sample_data(ps.top), tax_table(ps.top))

top = names(sort(taxa_sums(ps.top), decreasing=TRUE))[1:30]

ps.top = prune_taxa(top, ps.top)
otu_table(ps.top) = otu_table(ps.top) +1
p = plot_heatmap(ps.top, sample.label = "Name", taxa.label="Genus", sample.order = c(ncont,stan)) + geom_tile()
p = p + 
  guides(fill = guide_legend(title="asinh abundance")) + xlab("Sample")
p
```



### Create a list of true ASVs in each diluted sample

```{r}
true.com.ASV = taxa_names(ps)[c(2:8,11,17,22,37)]
# true.com.ASV = taxa_names(ps)[which((tax_table(ps)[,6] %in% c("Bacillus","Listeria","Staphylococcus", "Lactobacillus", "Escherichia/Shigella", "Enterococcus", "Salmonella", "Pseudomonas")))]

# true.com.ASV = taxa_names(ps)[which((tax_table(ps)[,6] %in% c("Bacillus","Listeria","Staphylococcus", "Lactobacillus", "Escherichia/Shigella", "Enterococcus", "Salmonella", "Pseudomonas"))&(!is.na(tax_table(ps)[,7])))]

diluted.sample.names = sample_names(ps)[3:10]

trueSeq = function(sample.name, true.com.ASV){
  df.sample.i = data.frame(ot = otu_table(ps)[, sample.name])
  names(df.sample.i) = "ot"
  df.sample.i = mutate(df.sample.i, ASV = rownames(df.sample.i))
  df.sample.i.true.seq = filter(df.sample.i, (ot > 0) & (as.character(ASV) %in% true.com.ASV))
  true.seq.sample.i = as.character(df.sample.i.true.seq$ASV)
  return(true.seq.sample.i)
}


true.seq.all.samples = lapply(diluted.sample.names, FUN = trueSeq, true.com.ASV = true.com.ASV)

true.seq.all.samples
```

Number of true ASVs in each dilution series sample
```{r}
lapply(true.seq.all.samples, function(x) {length(x)})
```
Number of unique true ASV in all samples
```{r}
length(unique(unlist(true.seq.all.samples)))
```


### Check the percentage of eleven ASVs in each dilution series sample

```{r}
ps.prop = transform_sample_counts(ps, function(otu) otu/sum(otu)*100)
ps.true = prune_taxa(unique(unlist(true.seq.all.samples)), ps)
ps.prop.true = prune_taxa(taxa_names(ps.true), ps.prop)
dt = otu_table(subset_samples(ps.prop.true, 
  SampleType == "Standard")) %>% data.frame()
colnames(dt) = sample_data(subset_samples(ps.prop.true, 
  SampleType == "Standard"))$Name
#rownames(dt) = df.ASV$ASV.Genus[which(as.character(df.ASV$ASV.Genus.Species) %in% rownames(dt))]
rownames(dt) = df.ASV$ASV.Genus.Species[which(as.character(df.ASV$ASV.Genus.Species) %in% rownames(dt))]
library(knitr)
kable(dt)
```


##  BARBI LDA for Zymo Data

We have only one block of samples.

```{r adding_blocks}
blocks = rep("Set1", nsamples(ps))

sample_data(ps)$block = blocks
```

Identify the species that are not present in at least one `SampleType == Standard` sample and removed them from the phyloseq object. Label these species as contaminants. 

```{r filter_taxa}
ps = prune_taxa(taxa_sums(ps) > 0, ps)
ps.standard = subset_samples(ps, SampleType %in% c("Standard"))
prevTaxaP = apply(otu_table(ps.standard), 1, function(x){sum(x>0)})

Contaminants1 = names(prevTaxaP)[prevTaxaP == 0]
length(Contaminants1)
```

```{r}
ps = prune_taxa(prevTaxaP > 0, ps)
ps
```

We identifed 142 ASVs not is any dilution series samples and they are classified as contaminants before using BARBI LDA.

  
See a summary of the `Standard` and `Negative` samples in each block. 

```{r summary_stat}
table(sample_data(ps)$SampleType, sample_data(ps)$block)
```

```{r}
colSums(otu_table(ps))
```

###      Prepare the phyloseq object for the Bayesian inference

We use Bayesian inference to identify contaminants in each block separately to account for the batch-effects of contamination. 

Thus, split the phyloseq object into multiple phyloseq objects corresponding to each block, and store the phyloseq objects as a list of phyloseq objects, `psByBlock`. 

Select negative control samples from each block and store as a list of phyloseq objects, `psNCbyBlock`. 

Select all species that have a prevalence of zero (i.e., have zero reads) in all negative control samples for each block and store as a list of phyloseq objects, `psallzeroInNC`.

Select all plasma samples from each block and store as a list of phyloseq objects, `psPlByBlock`.

```{r list_of_phyloseq}
source("psBlockResults.R")
psBlockResult = psBlockResults(ps, 
  sampleTypeVar = "SampleType", caselevels = c("Standard"), controllevel="Negative", sampleName = "Name", blockVar = "block")

psByBlock = psBlockResult[[1]]
psNCbyBlock = psBlockResult[[2]]
psallzeroInNC = psBlockResult[[3]]
psPlByBlock = psBlockResult[[4]]

# st = sample_names(psByBlock[[1]])[-c(4:10)]
# psByBlock[[1]] = subset_samples(psByBlock[[1]], SampleCode %in% st)
```

## Make an LDA object

otu-table coluns to list (all dilution and negative control)
```{r}
ot = otu_table(psByBlock[[1]]) %>% data.frame
make.lda = list()
for(i in 1:dim(ot)[2]){
  df.i = data.frame(ASV = seq(0, (length(ot[,i])-1)), cout = ot[,i]) 
  df.i = filter(df.i, cout > 0) %>% as.matrix
  colnames(df.i) = NULL
  make.lda[[i]] = t(df.i)
}

taxa.name = taxa_names(psByBlock[[1]])
```

```{r}
theme_set(theme_bw())

set.seed(8675309)

K <- 10 ## Num clusters

N = nsamples(psByBlock[[1]])

result <- lda.collapsed.gibbs.sampler(make.lda,
                                       K,  ## Num clusters
                                       taxa.name,
                                       25,  ## Num iterations
                                       0.1,
                                       0.1,
                                       compute.log.likelihood=TRUE) 

df = result$document_sums %>% data.frame #A K \times D matrix where each entry is an integer indicating the number of times words in each document (column) were assigned to each topic (column).
colnames(df) = sample_names(psByBlock[[1]])

rownames(df) = paste0("Communtiy ", seq(1, dim(df)[1]))
#View(df)

top.species.in.each.topic = top.topic.words(result$topics, 12, by.score = TRUE)
colnames(top.species.in.each.topic) = paste0("Communtiy ", seq(1, dim(top.species.in.each.topic)[2]))

topic.proportions <- t(result$document_sums) / colSums(result$document_sums) # sample by topic matrix

# colnames(topic.proportions) <- apply(top.species.in.each.topic, 2, paste, collapse=" ")
colnames(topic.proportions) = paste0("Communtiy ", seq(1, dim(top.species.in.each.topic)[2]))
rownames(topic.proportions) = sample_names(psByBlock[[1]])

#View(topic.proportions)

topic.proportions.df <- melt(cbind(data.frame(topic.proportions), sampleID = factor(sample_names(psByBlock[[1]]))), variable.name="topic", id.vars = "sampleID")  

# ggplot(data = topic.proportions.df, aes(x = topic), fill = document) + geom_bar() + coord_flip() +
#   facet_wrap(~ document, ncol=5)
ggplot(topic.proportions.df, aes(x=topic, y=value, fill=sampleID), ylab="proportion") +
  geom_bar(stat="identity") +
  theme(axis.text.x = element_text(angle=90, hjust=1)) +
  coord_flip() +
  facet_wrap(~ sampleID, ncol=5) +
  guides(fill =FALSE) + xlab("Communtiy") +
  ylab("Community proportion")

```












otu-table coluns to list (only negative controls)
```{r}
ot = otu_table(psNCbyBlock[[1]]) %>% data.frame
make.lda = list()
for(i in 1:dim(ot)[2]){
  df.i = data.frame(ASV = seq(0, (length(ot[,i])-1)), cout = ot[,i]) 
  df.i = filter(df.i, cout > 0) %>% as.matrix
  colnames(df.i) = NULL
  make.lda[[i]] = t(df.i)
}

taxa.name = taxa_names(psByBlock[[1]])
```

```{r}
theme_set(theme_bw())

set.seed(8675309)

K <- 10 ## Num clusters

result.neg.cont <- lda.collapsed.gibbs.sampler(make.lda,
                                       K,  ## Num clusters
                                       taxa.name,
                                       25,  ## Num iterations
                                       0.1,
                                       0.1,
                                       compute.log.likelihood=TRUE) 

df.nc = result.neg.cont$document_sums %>% data.frame #A K \times D matrix where each entry is an integer indicating the number of times words in each document (column) were assigned to each topic (column).
colnames(df.nc) = sample_names(psNCbyBlock[[1]])

#View(df.nc)

top.species.in.each.topic.nc = top.topic.words(result.neg.cont$topics, 2, by.score = TRUE)

topic.proportions.nc <- t(result.neg.cont$document_sums) / colSums(result.neg.cont$document_sums) # sample by topic matrix

# colnames(topic.proportions) <- apply(top.species.in.each.topic, 2, paste, collapse=" ")
colnames(topic.proportions.nc) = paste0("Communtiy ", seq(1, dim(top.species.in.each.topic.nc)[2]))

rownames(topic.proportions.nc) = sample_names(psNCbyBlock[[1]])

#View(topic.proportions.nc)

topic.proportions.df.nc <- melt(cbind(data.frame(topic.proportions.nc), sampleID = factor(sample_names(psNCbyBlock[[1]]))), variable.name="topic", id.vars = "sampleID")  


# ggplot(data = topic.proportions.df, aes(x = topic), fill = document) + geom_bar() + coord_flip() +
#   facet_wrap(~ document, ncol=5)
ggplot(topic.proportions.df.nc, aes(x=topic, y=value, fill=sampleID), ylab="proportion") +
  geom_bar(stat="identity") +
  theme(axis.text.x = element_text(angle=90, hjust=1)) +
  coord_flip() +
  facet_wrap(~ sampleID, ncol=5) +
  guides(fill =FALSE) + xlab("Communtiy") +
  ylab("Community proportion")
```
