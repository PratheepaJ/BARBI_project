---
title: 'SIRS BARBI Aanalysis'
author: "PJ, HC, SH, DR"
date: '`r format(Sys.time(), "%B %d, %Y")`'
header-includes:
  - \usepackage{color}
output: 
    html_document:
        toc: true
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r install_packages, eval=FALSE}
pkgs <- c("DESeq2","phyloseq","dplyr",
          "tidyr","R.utils","BiocParallel",
          "doParallel","parallel","HDInterval",
          "grid","xtable","gtable",
          "gridExtra","BiocStyle","magrittr",
          "devtools","ggplot2")

if (!requireNamespace("BiocManager")){
  install.packages("BiocManager")
}
    
BiocManager::install(setdiff(pkgs, installed.packages()), update = TRUE)

devtools::install_github("PratheepaJ/BARBI",auth_token = "33c5f43cc3f1772c19a441e15fc9478c3bf91b67")
```


Load packages:
```{r load_packages}
#library(BARBI)
library(devtools)
library(phyloseq)
library(DESeq2)
library(dplyr)
library(tidyr)
library(R.utils)
library(BiocParallel)
library(doParallel)
library(parallel)
library(HDInterval)
library(grid)
library(xtable)
library(gtable)
library(gridExtra)
library(BiocStyle)
library(magrittr)
library(ggplot2)
sourceDirectory("./R")
#sourceDirectory("/Users/jpratheepa31/Dropbox/GitHub/SIRS_project/Final_Results_For_Manuscript/R")
```


Set the computational resources
```{r}
ncores = as.integer(Sys.getenv("SLURM_NTASKS"))
if(is.na(ncores)) ncores <- parallel::detectCores()
```

##      Load the phyloseq object

Load R file to create a phyloseq object from Kraken files: (this directory should be set according to the files directory). I saved the phyloseq as `ps_sirs_updated_may_1_2018.rds`. 


Read phyloseq object 
```{r Read-phyloseq}
ps <- readRDS("./Data/ps_sirs_updated_may_1_2018.rds")
ps
if(dim(otu_table(ps))[1]!=ntaxa(ps)){otu_table(ps) <- t(otu_table(ps))}

ps <- subset_samples(ps, !(Sample_Type == "Library_Control"))
```

### Replace labels and remove healthy subjects
```{r}
mapp <- readxl::read_excel("./Data/Pt_and_P.xlsx")
sample_names(ps)[which(sample_names(ps) %in% mapp$P)] <- mapp$Pt
sample_data(ps)$SampleCode <- sample_names(ps)

ps <- subset_samples(ps, !(SampleType == "Healthy"))
```

###  Identifying batches

In a previous PCA analysis of this dataset, the samples separated into three separate clusters, which correlated with three groups of DNA extraction batches. 

To reduce the batch-effects of contamination, we specified three "blocks" of samples, and analyzed each block separately with BARBI. 

```{r adding_blocks}
set1 <- c("1","2","3","4","11","12")
set2 <- c("5","6","7","8","9","10")
setP <- "P"
ext.num <- sample_data(ps)$Extraction_Number

blocks <- ifelse(ext.num %in% set1, "Set1", ifelse(ext.num %in% set2, "Set2","SetP"))

sample_data(ps)$block <- blocks
```


### Remove healthy subjects

Subset samples such that only patient plasma and negative control samples are included in the final phyloseq object. 

```{r choose_samples}
ps <- subset_samples(ps,Sample_Type %in% c("Plasma","Control"))
saveRDS(ps, "./Data/psJan18.rds")
```

###  Total reads 

Compute total reads in each plasma and negative control sample. Bowtie2 is then used to identifed non-human reads. 

```{r}
summary(sample_data(subset_samples(ps, Sample_Type == "Plasma"))$Reads)/(2*10^6)
summary(sample_data(subset_samples(ps, Sample_Type == "Control"))$Reads)/(2*10^6)
```

### Non-human reads (in ten thousands)

```{r}
summary(sample_data(subset_samples(ps, Sample_Type == "Plasma"))$Non.Human.Reads)/(2*10^4)
summary(sample_data(subset_samples(ps, Sample_Type == "Control"))$Non.Human.Reads)/(2*10^5)
```

### Percentage of non-human reads

```{r}
summary(sample_data(subset_samples(ps, Sample_Type == "Plasma"))$Percent.Non.Human)
summary(sample_data(subset_samples(ps, Sample_Type == "Control"))$Percent.Non.Human)
```


###  heatmap

```{r}
ps.top <- ps 

# do arcsinh transformation
ot <- otu_table(ps.top) %>% data.frame %>% as.matrix

geo_mean <- function(x) {
        if(all(x == 0)){
            val <- 0
        }else{
            val <- exp(sum(log(x[x > 0]))/length(x))
        }
        return(val)
    }

geom_mean_row <- apply(ot, 1, FUN = geo_mean)


sj <- estimateSizeFactorsForMatrix(ot, median, geoMeans = geom_mean_row)
ot.trans <- t(asinh(t(ot)/sj))
ps.top <- phyloseq(otu_table(ot.trans, taxa_are_rows = TRUE), sample_data(ps.top), tax_table(ps.top))
    
# choose top 30 species in plasma samples for heatmap
top <- names(sort(taxa_sums(subset_samples(ps.top, Sample_Type == "Plasma")), decreasing=TRUE))[1:30]

ps.top <- prune_taxa(top, ps.top)
otu_table(ps.top) <- otu_table(ps.top) +1

# order sample by plasma and control
df <- data.frame(sample_data(ps)$SampleCode, sample_data(ps)$Sample_Type)
sam.order <- as.character(df$sample_data.ps..SampleCode)

p <- plot_heatmap(ps.top, sample.label = "SampleCode", taxa.label="Species", taxa.order = top, sample.order = sam.order) + guides(fill = guide_legend(title="asinh abundance")) + facet_wrap(~block, scales = "free_x")
p
ggsave("./Figures/heatmap_SIRS_top.eps", plot = p, width = 20, height = 8)
```


```{r}
ps.top.cont <- ps 

# do arcsinh transformation
ot <- otu_table(ps.top.cont) %>% data.frame %>% as.matrix

geo_mean <- function(x) {
        if(all(x == 0)){
            val <- 0
        }else{
            val <- exp(sum(log(x[x > 0]))/length(x))
        }
        return(val)
    }

geom_mean_row <- apply(ot, 1, FUN = geo_mean)


sj <- estimateSizeFactorsForMatrix(ot, median, geoMeans = geom_mean_row)
ot.trans <- t(asinh(t(ot)/sj))
ps.top.cont <- phyloseq(otu_table(ot.trans, taxa_are_rows = TRUE), sample_data(ps.top.cont), tax_table(ps.top.cont))
    
# choose top 30 species in plasma samples for heatmap
top <- names(sort(taxa_sums(subset_samples(ps.top.cont, Sample_Type == "Control")), decreasing=TRUE))[1:30]

ps.top.cont <- prune_taxa(top, ps.top.cont)
otu_table(ps.top.cont) <- otu_table(ps.top.cont) +1

# order sample by plasma and control
df <- data.frame(sample_data(ps)$SampleCode, sample_data(ps)$Sample_Type)
sam.order <- as.character(df$sample_data.ps..SampleCode)

p <- plot_heatmap(ps.top.cont, sample.label = "SampleCode", taxa.label="Species", taxa.order = top, sample.order = sam.order) + guides(fill = guide_legend(title="asinh abundance")) + facet_wrap(~block, scales = "free_x")
p
ggsave("./Figures/heatmap_SIRS_top_control.eps", plot = p, width = 20, height = 8)
```



###  Preprocessing

Identify the species that are not present in at least one plasma sample and removed those species from the phyloseq object. Label these species as contaminants. 

```{r filter_taxa}
ps <- prune_taxa(taxa_sums(ps) > 0, ps)
ps_plasma <- subset_samples(ps,Sample_Type %in% c("Plasma"))
prevTaxaP <- apply(otu_table(ps_plasma), 1 ,function(x){sum(x>0)})

Contaminants1 <- names(prevTaxaP)[prevTaxaP==0]
ps <- prune_taxa(prevTaxaP > 0,ps)
ps
```


Check the distribution of library size/sample depth to see whether there are samples with very small library sizes that should be dropped from the analysis.

```{r filter-samples}
totalReads <- colSums(otu_table(ps))
hist(log(totalReads), yaxs="i", xaxs="i", main="Distribution of total reads per sample", breaks=50)
```

See a summary of the plasma and negative control samples in each block. 

```{r summary_stat}
table(sample_data(ps)$Sample_Type, sample_data(ps)$block)
```

##  Bayesian Inference 

### Prepare the phyloseq object for the Bayesian inference

We use Bayesian inference to identify contaminants in each block separately to account for the batch-effects of contamination. 

Thus, we split the phyloseq object into multiple phyloseq objects corresponding to each block and store the phyloseq objects as a list of phyloseq objects, `psByBlock`. 

Select negative control samples from each block and store as a list of phyloseq objects, `psNCbyBlock`. 

Select all species that have a prevalence of zero (i.e., have zero reads) in all negative control samples for each block and store as a list of phyloseq objects, `psallzeroInNC`.

Select all plasma samples from each block and store as a list of phyloseq objects, `psPlByBlock`.

```{r list_of_phyloseq}
psBlockResult <- psBlockResults(ps, sampleTypeVar = "Sample_Type", caselevels = c("Plasma"), controllevel= "Control", sampleName = "SampleCode", blockVar = "block")

psByBlock <- psBlockResult[[1]]
psNCbyBlock <- psBlockResult[[2]]
psallzeroInNC <- psBlockResult[[3]]
psPlByBlock <- psBlockResult[[4]]

saveRDS(psByBlock,"./Results/psByBlock.rds")
```

### Use negative controls

Using the negative control samples and accounting for different library depths, we estimate the (gamma) probability density of the contaminants reads.

We use `stringent = TRUE` so that if $\mu_{0} < 1$, the sample mean of non-zero abundances will be used for $\mu_{0}$

```{r estimate_Cont_Intensity_ncontrols}
alphaBetaNegControl <- alphaBetaNegControl(psNCbyBlock = psNCbyBlock, stringent = TRUE)
```


### Estimate for the intensity parameter for the number of contaminant reads

Estimate the gamma density (shape and rate) for the intensity of contaminant reads using the scaling property of the gamma distribution. This gives an estimate for the intensity parameter $\lambda^{(c)}$ for the contaminant reads.


```{r estimate_Cont_Intensity_plasma}
num_blks <- length(alphaBetaNegControl)
blks <- seq(1, num_blks) %>% as.list

gammaPrior_all_blks <- lapply(blks, function(x){
        gammaPrior <- alphaBetaContInPlasma(psPlByBlock = psPlByBlock, psallzeroInNC = psallzeroInNC, blk = x, alphaBetaNegControl=alphaBetaNegControl)
        return(gammaPrior)
})
```


### Sample from the marginal posterior of the number of true reads

Sample from the marginal posterior of the number of true reads using the Metropolis-Hasting MCMC. Specifify the number of iterations in the MCMC using the option `itera`. 

Save the gamma density parameter estimates for the number of contaminant reads and the posterior samples for the number of true reads.

We suggest to use 10,000 iterations. 

```{r sampling_post_true_int}
t1 <- proc.time()

post_all_blocks <- lapply(blks, function(x){
        post_int_all_taxa <- samplingPosterior(psPlByBlock = psPlByBlock,
          blk = x,
          gammaPrior_Cont = gammaPrior_all_blks[[x]],
          itera = 100,
          ncores = ncores)
        return(post_int_all_taxa)
})

proc.time()-t1


gammaPrior_posTrueSing_all_blocks <- list(gammaPrior_all_blks, post_all_blocks)

saveRDS(gammaPrior_posTrueSing_all_blocks, file= "./Results/gammaPrior_posTrueSing_all_blocks_SIRS.rds")
```



##  Display the results

### Make summaires from the BARBI results.

Choose the number of MCMC to be removed using the option `burnIn`.  It must be less than `itera`.

Choose the coverage probability to construct the highest posterior density interval using the option `cov.pro`.

The suggested burnIn is 5000 for itera = 10000.

The output table for each sample displays the following:

-   Species = species names that are not contaminant,
-   xj  =   observed reads for the species in that sample,
-   l_s =   lower limit of the highest (posterior) density interval (credible interval) for the number of true reads,
(the chance that the true intensity lies between l_s and l_u is the cov.pro)
-   u_s =   upper limit of the highest (posterior) density interval (credible interval) for the number of true reads,
-   l_b = lower limit of the highest density interval for the contaminant reads,
-   u_b = upper limit of the highest density interval for the contaminant reads,
-   all_zero_nc = whether all the negative control samples with zero reads for that particular species


Taxa/ASVs/Species are labeled as contaminants if the lower limit of the true reads (l_s) is smaller than the upper limit of the contaminant reads (u_b). 


```{r make_tables}
itera <- 100
burnIn <- 5
cov_pro <- .95
mak_tab <- TRUE # need to change to TRUE if you want to make tables
#psByBlock <- readRDS("./Results/psByBlock2.rds")

gammaPrior_posTrueSing_all_blocks <- readRDS("./Results/gammaPrior_posTrueSing_all_blocks_SIRS.rds")

gammaPrior_all_blks <- gammaPrior_posTrueSing_all_blocks[[1]]
post_all_blocks <- gammaPrior_posTrueSing_all_blocks[[2]]



all_real_taxa_lt <- list()

for(blk in 1:num_blks){

                taxa_post_all_sam <- post_all_blocks[[blk]]
                gammPrior <- gammaPrior_all_blks[[blk]]

                total_summary_table <- NULL

                all_real_taxa <- character()

                for(sam in 1:nsamples(psPlByBlock[[blk]])){

                        taxa_post <- taxa_post_all_sam[[sam]]
                        acceptance <- list()
                        exp_post_s <- list()
                        lower_s <- list()
                        upper_s <- list()
                        lower_b <- list()
                        upper_b <- list()
                        all_zero_nc <- list()
                        signal_to_noise_ratio_lower <- list()
                        

                        for(taxa in 1:length(taxa_post)){
                                
                                burnIn  <- burnIn
                                acceptance[[taxa]]  <-  1-mean(duplicated(taxa_post[[taxa]][-(1:burnIn),]))

                                exp_post_s[[taxa]] <- mean(taxa_post[[taxa]][-(1:burnIn),])

                                hdi_v <- hdi(taxa_post[[taxa]][-(1:burnIn),], credMass = cov_pro)
                                lower_s[[taxa]] <- round(hdi_v[1], digits = 0)
                                upper_s[[taxa]] <- round(hdi_v[2], digits = 0)
                                b_int <- rgamma((itera-burnIn+1), shape = gammPrior[[sam]][[1]][taxa], rate = gammPrior[[sam]][[2]][taxa])

                                hdi_b <- hdi(b_int, credMass = cov_pro)
                                lower_b[[taxa]] <- round(hdi_b[1], digits = 0)
                                upper_b[[taxa]] <- round(hdi_b[2], digits = 0)


                                all_zero_nc[[taxa]] <-  gammPrior[[sam]][[5]][taxa]
                                
                                sig_noise_ratio <- taxa_post[[taxa]][-(1:burnIn),]/b_int
                        
                        sig_noise_ra_hdi <- hdi(sig_noise_ratio, credMass = cov_pro)
                        signal_to_noise_ratio_lower[[taxa]] <- sig_noise_ra_hdi[[1]]
                      
                        
                        }


                        df <- data.frame(Species=taxa_names(psPlByBlock[[blk]]),
                                         xj=as.numeric(gammPrior[[sam]][[3]]),
                                         l_s = unlist(lower_s),
                                         u_s = unlist(upper_s),
                                         l_b = unlist(lower_b),
                                         u_b = unlist(upper_b),
                                         all_zero_nc = unlist(all_zero_nc)
                                         )

                        df <- arrange(filter(df,((l_s>u_b)&(l_s>0))), desc(xj))


                        if(dim(df)[1]==0){
                                df <- data.frame(Species="Negative",
                                                 xj="Negative",
                                                 l_s="Negative",
                                                 u_s="Negative",
                                                 l_b ="Negative",
                                                 u_b="Negative",
                                                 all_zero_nc = "Negative")
                        }


                        all_real_taxa <- c(all_real_taxa,
                                           as.character(df$Species))
                        if(mak_tab){
                                filname <- paste("./Results/",
                                                 sample_names(psPlByBlock[[blk]])[sam],
                                                 ".png",
                                                 sep="")

                                png(filname, height = 600, width = 750)

                                df_p <- tableGrob(df)
                                title <- textGrob(sample_names(psPlByBlock[[blk]])[sam], gp = gpar(fontsize = 12))

                                padding <- unit(0.5,"line")

                                df_p <- gtable_add_rows(
                                        df_p, heights = grobHeight(title) + padding, pos = 0
                                )

                                df_p <- gtable_add_grob(
                                        df_p, list(title),
                                        t = 1, l = 1, r = ncol(df_p) 
                                )

                                grid.newpage()
                                grid.draw(df_p)
                                dev.off()
                        }


                        all_real_taxa <- unique(all_real_taxa)
                }

                all_real_taxa_lt[[blk]] <- all_real_taxa
        }

```


### Construct a phyloseq object with the true species and plasma samples

```{r make_phyloseq}
saveRDS(all_real_taxa_lt, "./Results/all_real_taxa_SIRS.rds")
all_real_taxa_lt <- readRDS("./Results/all_real_taxa_SIRS.rds")
all_real_taxa_lt <- unlist(all_real_taxa_lt)
all_real_taxa_lt <- all_real_taxa_lt[which(!all_real_taxa_lt == "Negative")]
ps_decon <- prune_taxa(all_real_taxa_lt, subset_samples(ps, Sample_Type %in% "Plasma"))
saveRDS(ps_decon,"./Results/ps_decon.rds")
```

### 
```{r}
sample_data(ps_decon)$block <- factor(sample_data(ps_decon)$block)
levels(sample_data(ps_decon)$block)
ps_decon_blk1 <- subset_samples(ps_decon, block == "Set1")
ps_decon_blk1 <-prune_taxa(taxa_sums(ps_decon_blk1) > 0, ps_decon_blk1)
ps_decon_blk1  
#View(otu_table(ps_decon_blk1) %>% data.frame)

ps_decon_blk2 <- subset_samples(ps_decon, block == "Set2")
ps_decon_blk2 <-prune_taxa(taxa_sums(ps_decon_blk2) > 0, ps_decon_blk2)
ps_decon_blk2 

ps_decon_blkP <- subset_samples(ps_decon, block == "SetP")
ps_decon_blkP <-prune_taxa(taxa_sums(ps_decon_blkP) > 0, ps_decon_blkP)
ps_decon_blkP 

```

### A list of contaminants
```{r }
contaminants <- taxa_names(ps)[!(taxa_names(ps) %in% taxa_names(ps_decon))]
saveRDS(contaminants, "./Results/contaminants_SIRS.rds")
```

##  Histograms
```{r}
library(tidyr)
itera <- 100
burnIn <- 5
cov_pro <- .95
mak_tab <- TRUE # need to change to TRUE if you want to make tables
#psByBlock <- readRDS("./Results/psByBlock2.rds")

gammaPrior_posTrueSing_all_blocks <- readRDS("./Results/gammaPrior_posTrueSing_all_blocks_SIRS.rds")

gammaPrior_all_blks <- gammaPrior_posTrueSing_all_blocks[[1]]
post_all_blocks <- gammaPrior_posTrueSing_all_blocks[[2]]

blk <- 1

taxa_post_all_sam <- post_all_blocks[[blk]]
gammPrior <- gammaPrior_all_blks[[blk]]


sample.names <- sample_names(psPlByBlock[[blk]])

for(j in 1: length(sample.names)){
    desired.sample.name <- sample.names[j]
    desired.sample.index <- which(sample_names(psPlByBlock[[blk]]) %in% desired.sample.name)
    tax_interested <- rownames(sort(otu_table(psPlByBlock[[blk]])[,desired.sample.index],decreasing = TRUE))[c(1:16)]
    tax_interested_ind <- which(as.character(taxa_names(psPlByBlock[[blk]])) %in% tax_interested)
    tax_names <- taxa_names(psPlByBlock[[blk]])[tax_interested_ind]
    #tax_names <- df.ASV$ASV.Genus[which(as.character(df.ASV$ASV.Genus.Species) %in%  tax_names)]
    
    
    taxa.post <- taxa_post_all_sam[[desired.sample.index]]
    
    burnIn <- 6
    signal.hist <- taxa.post[tax_interested_ind]
    signal.hist <- lapply(signal.hist,function(x){x[-(1:burnIn),]})
    signal.df <- data.frame(do.call("cbind", signal.hist))
    colnames(signal.df) <- tax_names
    signal.df$group <- rep("True",length=dim(signal.df)[1])
    
    bg <- list()
    for(ind in 1:length(tax_interested_ind)){
            bg[[ind]] <- rgamma(5000, shape=gammPrior[[desired.sample.index]][[1]][tax_interested_ind[ind]],rate = gammPrior[[desired.sample.index]][[2]][tax_interested_ind[ind]])
    }
    
    bg.df <- data.frame(do.call("cbind",bg))
    colnames(bg.df) <- tax_names
    bg.df$group <- rep("Contaminant",length=dim(bg.df)[1])
    
    bg.signal <- rbind(signal.df, bg.df)
    bg.signal$group <- as.factor(bg.signal$group)
    bg_sig_long <- tidyr::gather(bg.signal,key="Taxa",value="Reads",1:(dim(bg.signal)[2]-1))
    bg_sig_long$Taxa <- as.factor(bg_sig_long$Taxa)
    
    p <- ggplot(bg_sig_long, aes(x= Reads))+
            geom_density(aes(y = ..scaled.., fill = group, color = group),alpha = .2)+
            facet_wrap(~Taxa,scales = "free")+
            scale_fill_manual(values=c("blue","brown"))+
            scale_color_manual(values=c("blue","brown"))+
            ggtitle(desired.sample.name)+
            theme(plot.title = element_text(hjust = 0.5))+
            theme(legend.title=element_blank(), strip.text.x = element_text(size=5)) + xlab("") + ylab("")
    
    fileN <- paste0("Figures/","block_",blk,"_",desired.sample.name,"_histogram",".eps")
    ggsave(fileN, plot = p, width = 10, height = 5, units = "in")
}

```

##  Session Info 

```{r session_info}
sessionInfo()
```
